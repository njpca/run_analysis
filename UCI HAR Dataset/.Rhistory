arrange(cran2,ip_id)
arrange(cran2,desc(ip_id))
arrange(cran2,package,ip_id)
arrange(cran2,country,desc(r_version,ip_id))
arrange(cran2,country,desc(r_version),ip_id)
cran3<-select(cran,ip_id,package,size)
cran3
mutate(cran3,size_mb=size/2^20)
mutate(cran3,size_mb=size/2^20,size_gb=size_mb/2^10)
mutate(cran3,correct_size=size+1000)
summare(cran,avg_bytes=mean(size))
summarize(cran,avg_bytes=mean(size))
library(dplyr)
cran<-tbl_df(mydf)
rm("mydf")
cra
cran
?group_by()
?group_by
by_package<-group_by(cran,package)
by_package
summarize(by_package,mean(size))
pack_sum <- summarize(by_package,
count = n(),
unique = n_distinct(ip_id),
countries = n_distinct(country),
avg_bytes = mean(size))
pack_sum
submit()
pack_sum
quantile(pack_sum$count,probs=.99)
top_counts=filter(pack_sum,count>679)
top_counts<-filter(pack_sum,count>679)
top_counts
View(top_counts)
top_counts_sorted<-arrange(top_counts,count)
top_counts_sorted<-arrange(top_counts,desc(count))
View(top_counts_sorted)
quantile(pack_sum$unique, probs = 0.99
quantile(pack_sum$unique, probs = 0.99)
top_unique<-filter(pack_sum,unique>465)
View(top_unique)
top_unique_sorted<-arrange(top_unique,desc(unique))
View(top_unique_sorted)
submit()
submit()
submit()
View(result3)
submit()
submit()
submit()
submit()
submit()
url1<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
read.csv(file = url1)
rm(list=ls())
url1<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
read.csv(file = url1)
acsdat<-read.csv(file = url1)
acsdat[acsdat$ACR==3,]
acsdat[acsdat$ACR=="3",]
class(acsdat$ACR)
acsdat[acsdat$ACR==3L,]
acsdat[acsdat$AGS==6]
acsdat[acsdat$AGS==6,]
acsdat
acsdat$ACR
acsdat$ACR[1]
class(acsdat$ACR[1])
acsdat[as.numeric(acsdat$ACR)==3L,]
acsdat[as.numeric(acsdat$ACR)==3,]
require(dplyr)
tb1<-tbl_df(data = acsdat)
tb1
head(tb1)
class(acsdat)
rm(list=ls())
url1<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
tb1<-tbl_df(read.csv(file=url1))
head(tb1)
tb1<-tbl_df(read.csv(file=url1,header = T))
head(tb1)
tb1farm<-filter(tb1,ACR=3,AGS=6)
tb1farm<-filter(tb1,ACR==3,AGS==6)
head(tb1farm)
select(tb1farm,ACR,AGS)
acsdat$ACR
acsdat<-read.csv(file = url1)
acsdat$ACR
acsdat$ACR==1
acsdat$ACR==3
acsdat$ACR==3&acsdat$AGS==6
agricultureLogical<-acsdat$ACR==3&acsdat$AGS==6
which(agricultureLogical)
which(agricultureLogical)[1:3]
ans1<-which(agricultureLogical)[1:3]
require(jpeg)
install.packages("jpeg")
require(jpeg)
url2<-"https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg"
readJPEG(source = url2,native = T)
download.file(url=url2,destfile = "jeff.jpg")
jeff<-readJPEG(source = "jeff.jpg",native = T)
head(jeff)
head(jeff)
require(dplyr)
quantile(x = jeff,probs = c(.3,.8))
quantile(x = jeff,probs = c(0,.3,.8,1))
quantile(x = jeff,probs = c(.3,.8))
quantile(x = jeff,probs = c(.2,.7))
quantile(x = jeff,probs = c(.2,.7),na.rm=T)
quantile(x = jeff,probs = c(.3,.8),na.rm=T)
url3a<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
url3b<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
gdp<-read.csv(file=url3a,header=T)
edu<-read.csv(file=url3b,header=T)
head(gdp)
head(edu)
gdp<-read.csv(file=url3a)
head(gdp)
gdp<-read.csv(file=url3a,header=T,skip = 1)
head(gdp)
gdp<-read.csv(file=url3a,header=T,skip = 2)
head(gdp)
gdp<-read.csv(file=url3a,header=T,skip = 3)
head(gdp)
gdp<-read.csv(file=url3a,header=T,skip = 2)
head(gdp)
gdp<-read.csv(file=url3a,header=T,skip = 3)
head(gdp)
gdp<-read.csv(file=url3a,header=T,skip = 3,col.names = c("CountryCode","Ranking","Empty","Country","GDP"),colClasses = C(character,numeric,NULL,character,numeric),nrows = 5)
gdp<-read.csv(file=url3a,header=T,skip = 3,col.names = c("CountryCode","Ranking","Empty","Country","GDP"),colClasses = c(character,numeric,character,character,numeric),nrows = 5))
gdp<-read.csv(file=url3a,header=T,skip = 3,
col.names = c("CountryCode","Ranking","Empty","Country","GDP"),
colClasses = c(character,numeric,character,character,numeric),
nrows = 5)
gdp<-read.csv(file=url3a,header=T,skip = 3,
col.names = c("CountryCode","Ranking","Empty","Country","GDP"),
colClasses = c(character,numeric,character,character,numeric),
ncol = 5)
head(gdp)
gdp<-read.csv(file=url3a,header=T,skip = 3,
col.names = c("CountryCode","Ranking","Empty","Country","GDP"),
colClasses = c(character,numeric,character,character,numeric))
gdp<-read.csv(file=url3a,header=T,skip = 3,
col.names = c("CountryCode","Ranking","Empty","Country","GDP",NA,NA,NA,NA,NA),
colClasses = c(character,numeric,character,character,numeric))
gdp<-read.csv(file=url3a,header=T,skip = 3,
col.names = c("CountryCode","Ranking","Empty","Country","GDP",NA,NA,NA,NA,NA),
colClasses = c(character,numeric,character,character,numeric,character,character,character,character,character))
gdp<-read.csv(file=url3a,header=T,skip = 3)
head(gdp)
gdp<-gdp[,c(1,2,4,5)]
head(gdp)
class(gdp)
names(gdp)<-c("CountryCode","Ranking","Country","GDP")
head(gdp)
edu<-read.csv(file=url3b,header=T)
head(edu)
merge(x = gdp,y=edu,by = "CountryCode")
gdpedu<-merge(x = gdp,y=edu,by = "CountryCode")
head(gdpedu)
gdpedu<-gdpedu[order(Ranking),]
gdpedu<-gdpedu[order("Ranking"),]
gdpedu<-gdpedu[order("Ranking",decreasing = T),]
head(gdpedu)
head(gdpedu[,1:3])
tail(gdpedu[,1:3])
gdpedu<-merge(x = gdp,y=edu,by = "CountryCode")
head(gdpedu)
head(gdpedu[1:3])
tail(gdpedu[1:3])
gdpedu<-gdpedu[order("Ranking",decreasing = T),]
tail(gdpedu[1:3])
gdpedu<-merge(x = gdp,y=edu,by = "CountryCode")
tail(gdpedu[1:3])
gdpedu<-gdpedu[order(gdpedu$Ranking,decreasing = T),]
tail(gdpedu[1:3])
tail(gdpedu[,1:3])
head(gdpedu[1:3])
tail(gdpedu[,1:3])
gdpedu[,1:3]
gdpedu<-merge(x = gdp,y=edu,by = "CountryCode")
gdpedu$Ranking<-as.numeric(gdpedu$Ranking)
gdpedu<-gdpedu[order(gdpedu$Ranking,decreasing = T),]
head(gdpedu[1:3])
gdpedu<-merge(x = gdp,y=edu,by = "CountryCode")
gdpedu$Ranking<-as.numeric(gdpedu$Ranking)
gdpedu<-gdpedu[order(gdpedu$Ranking,decreasing = T),]
gdpedu[,1:3]
gdpedu[190,1:3]
gdpedu[13]
gdpedu[13,1:3]
gdp<-read.csv(file=url3a,header=T,skip = 3)
gdp<-gdp[,c(1,2,4,5)]
names(gdp)<-c("CountryCode","Ranking","Country","GDP")
edu<-read.csv(file=url3b,header=T)
head(gdp)
head(edu)
gdp$Ranking<-as.numeric(gdp$Ranking)
gdp$GDP<-as.numeric(gdp$GDP)
head(gdp)
gdp<-read.csv(file=url3a,header=T,skip = 3)
gdp<-gdp[,c(1,2,4,5)]
head(gdp)
gdp<-gdp[-1,c(1,2,4,5)]
gdp<-read.csv(file=url3a,header=T,skip = 3)
gdp<-gdp[-1,c(1,2,4,5)]
head(gdp)
gdp<-read.csv(file=url3a,header=T,skip = 3)
gdp<-gdp[-1,c(1,2,4,5)]
names(gdp)<-c("CountryCode","Ranking","Country","GDP")
head(gdp)
class(gdp$Ranking)
gdp$Ranking<-as.character(gdp$Ranking)
head(gdp)
gdp<-read.csv(file=url3a,header=T,skip = 3)
gdp<-gdp[-1,c(1,2,4,5)]
names(gdp)<-c("CountryCode","Ranking","Country","GDP")
class(gdp$Ranking)
gdp$Ranking<-as.numeric(as.character(gdp$Ranking))
class(gdp$Ranking)
head(gdp)
gdp$GDP<-as.numeric(as.character(gdp$GDP))
head(gdp)
gdp<-read.csv(file=url3a,header=T,skip = 3)
gdp<-gdp[-1,c(1,2,4,5)]
names(gdp)<-c("CountryCode","Ranking","Country","GDP")
gdp$Ranking<-as.numeric(as.character(gdp$Ranking))
head(gdp)
gdp<-read.csv(file=url3a,header=T,skip = 3)
gdp<-gdp[-1,c(1,2,4,5)]
names(gdp)<-c("CountryCode","Ranking","Country","GDP")
gdp$Ranking
gdp[191]
gdp[191,]
gdp[190,]
gdp[190:250,]
gdp[180:250,]
gdp[180:200,]
gdp[180:205,]
gdp[180:240,]
gdp<-gdp[2:232,c(1,2,4,5)]
gdp<-read.csv(file=url3a,header=T,skip = 3)
gdp<-gdp[2:232,c(1,2,4,5)]
names(gdp)<-c("CountryCode","Ranking","Country","GDP")
head(gdp)
head(gdp);tail(gdp)
gdp<-read.csv(file=url3a,header=T,skip = 3)
gdp<-gdp[2:236,c(1,2,4,5)]
names(gdp)<-c("CountryCode","Ranking","Country","GDP")
gdp[180:240,]
head(gdp);tail(gdp)
gdp<-read.csv(file=url3a,header=T,skip = 3)
gdp<-gdp[2:233,c(1,2,4,5)]
names(gdp)<-c("CountryCode","Ranking","Country","GDP")
gdp$Ranking<-as.numeric(as.character(gdp$Ranking))
head(gdp);tail(gdp)
head(edu);tail(edu)
edu<-edu[,c("CountryCode","Long.Name","Income.Group")]
head(edu);tail(edu)
edu<-edu[,c("CountryCode","Short.Name","Income.Group")]
edu<-read.csv(file=url3b,header=T)
edu<-edu[,c("CountryCode","Short.Name","Income.Group")]
head(edu);tail(edu)
head(gdp);tail(gdp)
head(edu);tail(edu)
source('~/.active-rstudio-document', echo=TRUE)
rm(list=ls())
url3a<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
url3b<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
gdp<-read.csv(file=url3a,header=T,skip = 3)
gdp<-gdp[2:234,c(1,2,4,5)]
names(gdp)<-c("CountryCode","Ranking","Country","GDP")
gdp$Ranking<-as.numeric(as.character(gdp$Ranking))
gdp$GDP<-as.numeric(gdp$GDP)
edu<-read.csv(file=url3b,header=T)
edu<-edu[,c("CountryCode","Short.Name","Income.Group")]
head(gdp);tail(gdp)
head(edu);tail(edu)
gdpedu<-merge(x = gdp,y=edu,by = "CountryCode")
head(gdpedu);tail(gdpedu)
url3a<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
url3b<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
gdp<-read.csv(file=url3a,header=T,skip = 3)
gdp<-gdp[2:234,c(1,2,4,5)]
head(gdp);tail(gdp)
url3a<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
url3b<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
gdp<-read.csv(file=url3a,header=T,skip = 3)
gdp<-gdp[2:234,c(1,2,4,5)]
names(gdp)<-c("CountryCode","Ranking","Country","GDP")
gdp$Ranking<-as.numeric(as.character(gdp$Ranking))
gdp$GDP<-as.numeric(gdp$GDP)
edu<-read.csv(file=url3b,header=T)
edu<-edu[,c("CountryCode","Short.Name","Income.Group")]
head(gdp);tail(gdp)
head(edu);tail(edu)
url3a<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
url3b<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
gdp<-read.csv(file=url3a,header=T,skip = 3)
gdp<-gdp[2:234,c(1,2,4,5)]
names(gdp)<-c("CountryCode","Ranking","Short.Name","GDP")
gdp$Ranking<-as.numeric(as.character(gdp$Ranking))
gdp$GDP<-as.numeric(gdp$GDP)
edu<-read.csv(file=url3b,header=T)
edu<-edu[,c("CountryCode","Short.Name","Income.Group")]
head(gdp);tail(gdp)
head(edu);tail(edu)
gdpedu<-merge(x = gdp,y=edu,by = "Short.Name")
head(gdpedu);tail(gdpedu)
url3a<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
url3b<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
gdp<-read.csv(file=url3a,header=T,skip = 3)
gdp<-gdp[2:234,c(1,2,4,5)]
names(gdp)<-c("CountryCode","Ranking","Country","GDP")
gdp$Ranking<-as.numeric(as.character(gdp$Ranking))
gdp$GDP<-as.numeric(gdp$GDP)
edu<-read.csv(file=url3b,header=T)
edu<-edu[,c("CountryCode","Short.Name","Income.Group")]
head(gdp);tail(gdp)
head(edu);tail(edu)
gdpedu<-merge(x = gdp,y=edu,by = "CountryCode")
head(gdpedu);tail(gdpedu)
gdpedu[13,]
gdpedu<-gdpedu[order(gdpedu$Ranking,decreasing = T),]
gdpedu[13,]
gdpedu[13,"Short.Name"]
View(gdpedu)
require(dplyr)
incomegroup<-group_by(.data = gdpedu,Income.Group)
summarize(incomegroup,meanrank=mean(Ranking))
summarize(incomegroup,meanrank=mean(Ranking,na.rm=T))
quantile(gdpedu$Ranking,probs = c(.2,.4,.6,.8))
quantile(gdpedu$Ranking,probs = c(.2,.4,.6,.8),na.rm=T)
filter(gdpedu,Income.Group="Lower middle income")
filter(gdpedu,Income.Group=="Lower middle income")
filter(gdpedu,Income.Group=="Lower middle income",Ranking<39)
ans5<-length(filter(gdpedu,Income.Group=="Lower middle income",Ranking<39))
ans5
require(jpeg)
url2<-"https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg"
download.file(url=url2,destfile = "jeff.jpg")
jeff<-readJPEG(source = "jeff.jpg",native = T)
head(jeff)
tail(jeff)
unique(jeff)
length(jeff)
str(jeff)
View(jeff)
jpeg(jeff)
?jpeg
url2<-"https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg"
download.file(url=url2,destfile = "jeff.jpg",method="curl")
jeff<-readJPEG(source = "jeff.jpg",native = T)
ans2<-quantile(x = jeff,probs = c(.3,.8),na.rm=T)
ans2
download.file(url=url2,destfile = "jeff.jpg")
jeff<-readJPEG(source = "jeff.jpg",native = T)
ans2<-quantile(x = jeff,probs = c(.3,.8),na.rm=T)
ans2
ans2<-quantile(x = jeff,probs = c(0.3,0.8),na.rm=T)
ans2
ans2<-quantile(x = jeff,probs = c(0.3,0.8),na.rm=F)
ans2
ans2<-quantile(x = jeff,probs = c(0.3,0.8))
ans2
summarize(incomegroup,meanrank=mean(Ranking,na.rm=T))
quantile(gdpedu$Ranking,probs = c(.2,.4,.6,.8),na.rm=T)
filter(gdpedu,Income.Group=="Lower middle income",Ranking<39)
getwd()
setwd(".\\")
getwd()
setwd("\\")
getwd()
setwd("C:/Users/npappas/Documents")
getwd()
setwd("C:/Users/npapp/Documents")
getwd()
getwd()
trainy<-read.table(file=".\\UCI HAR Dataset\\train\\y_train.txt",header=F,
col.names = "Labels",colClasses = "character")
getwd()
setwd("/UCI Har Dataset")
setwd("/UCI HAR Dataset")
setwd("/UCI HAR Dataset/")
setwd(".\\UCI HAR Dataset")
getwd()
#Run_Analysis
##Clear Environment and Load Packages
rm(list=ls())
require(dplyr)
require(tidyr)
#Step 1: "Merges the training and test sets to create one data set.
##Loading Data
##Assigning Training Data to Variables
trainy<-read.table(file=".\\train\\y_train.txt",header=F,
col.names = "Labels",colClasses = "character")
trainsubject<-read.table(file = ".\\train\\subject_train.txt",header=F,
col.names = "Subject")
trainx<-read.table(file=".\\train\\X_train.txt",header=F)
##Loading Testing Data to Variables
testy<-read.table(file=".\\test\\y_test.txt",header=F,
col.names = "Labels")
testsubject<-read.table(file = ".\\test\\subject_test.txt",header=F,
col.names = "Subject")
testx<-read.table(file=".\\test\\X_test.txt",header=F)
##Merging Training and Testing Data
testdata<-cbind(testx,set="test",testsubject,testy)
traindata<-cbind(trainx,set="train",trainsubject,trainy)
fulldata<-rbind(testdata,traindata)
#Step 2. "Extracts only the measurements on the mean and standard deviationfor each measurement."
##Determining which measurements are on mean and std. dev.
###Loading feature labels
featurelabels<-read.table(".\\features.txt",header=F)
###Generating T/F vector for contains "std" or "mean", plus TRUEs for other columns
meansandstds<-c(grepl("std",x=featurelabels[,2])|grepl("mean",x = featurelabels[,2]),T,T,T)
###Subsets fulldata by columns which are TRUE for subsetting T/F vector
subdata<-fulldata[,meansandstds]
#Step 3. "Uses descriptive activity names to name the activities in the data set"
###Loading Activity Labels
activities<-read.table(".\\activity_labels.txt")
###Replacing numeric Activity Labels with Descriptive Activity Names
fulldata$Labels<-as.character(factor(x=fulldata$Labels,levels=1:6,labels=as.character(activities[,2])))
subdata$Labels<-as.character(factor(x=subdata$Labels,levels=1:6,labels=as.character(activities[,2])))
#Step 4. "Appropriately labels the data set with descriptive variable names."
##Due to length of some variable names exceeding max length, abbreviations must be used.
featurelabels[,2]<-as.character(featurelabels[,2])
featurelabels[,2]<-gsub(x = featurelabels[,2],pattern = "Body",replacement="B",ignore.case = T)
featurelabels[,2]<-gsub(x = featurelabels[,2],pattern = "Gravity",replacement="Gr",ignore.case = T)
featurelabels[,2]<-gsub(x = featurelabels[,2],pattern = "Gyro",replacement="Gy",ignore.case = T)
featurelabels[,2]<-gsub(x = featurelabels[,2],pattern = "Jerk", replacement = "Jk",ignore.case = T)
featurelabels[,2]<-gsub(x = featurelabels[,2],pattern = "bandsEnergy",replacement = "bE",ignore.case = T)
featurelabels[,2]<-gsub(x = featurelabels[,2],pattern = "correlation",replacement = "corr",ignore.case = T)
featurelabels[,2]<-gsub(x = featurelabels[,2],pattern = "kurtosis",replacement = "Kurt",ignore.case = T)
##Once feature labels have been abbreviated, appply to full and subdata using grepl T/F vector approach.
names(fulldata)<-c(featurelabels[,2],"set","Subject","Labels")
names(subdata)<-c(featurelabels[grepl("std",x=featurelabels[,2])|grepl("mean",x = featurelabels[,2]),2],"set","Subject","Labels")
#Step 5. "From the data set in step 4, creates a second, independent tidy data set with the average of each variable for each activity and each subject."
subdatatbl<-tbl_df(data = subdata)
bysubjact<-group_by(.data = subdatatbl,Subject,Labels)
summed<-summarise_all(bysubjact,.funs = mean)
avgdata<-as.data.frame(x=summed)
#Final Step: EXPORT!
write.csv(x=subdata,file="Mean and Standard Deviation Data.csv")
write.table(x=avgdata,file="Averages by Subject and Activity Data.txt",row.names = F)
#Appendix: Appending Features File with Shorthand Version
featurelabelsfull<-(cbind(read.table(".\\features.txt",header=F),featurelabels[,2]))
names(featurelabelsfull)<-c("Index","Full","Shorthand")
write.csv(x = featurelabelsfull,file = ".\\features.txt",row.names = F)
#Run_Analysis
##Clear Environment and Load Packages
rm(list=ls())
require(dplyr)
require(tidyr)
#Step 1: "Merges the training and test sets to create one data set.
##Loading Data
##Assigning Training Data to Variables
trainy<-read.table(file=".\\train\\y_train.txt",header=F,
col.names = "Labels",colClasses = "character")
trainsubject<-read.table(file = ".\\train\\subject_train.txt",header=F,
col.names = "Subject")
trainx<-read.table(file=".\\train\\X_train.txt",header=F)
##Loading Testing Data to Variables
testy<-read.table(file=".\\test\\y_test.txt",header=F,
col.names = "Labels")
testsubject<-read.table(file = ".\\test\\subject_test.txt",header=F,
col.names = "Subject")
testx<-read.table(file=".\\test\\X_test.txt",header=F)
##Merging Training and Testing Data
testdata<-cbind(testx,set="test",testsubject,testy)
traindata<-cbind(trainx,set="train",trainsubject,trainy)
fulldata<-rbind(testdata,traindata)
#Step 2. "Extracts only the measurements on the mean and standard deviationfor each measurement."
##Determining which measurements are on mean and std. dev.
###Loading feature labels
featurelabels<-read.table(".\\features.txt",header=F)
###Generating T/F vector for contains "std" or "mean", plus TRUEs for other columns
meansandstds<-c(grepl("std",x=featurelabels[,2])|grepl("mean",x = featurelabels[,2]),T,T,T)
###Subsets fulldata by columns which are TRUE for subsetting T/F vector
subdata<-fulldata[,meansandstds]
#Step 3. "Uses descriptive activity names to name the activities in the data set"
###Loading Activity Labels
activities<-read.table(".\\activity_labels.txt")
###Replacing numeric Activity Labels with Descriptive Activity Names
fulldata$Labels<-as.character(factor(x=fulldata$Labels,levels=1:6,labels=as.character(activities[,2])))
subdata$Labels<-as.character(factor(x=subdata$Labels,levels=1:6,labels=as.character(activities[,2])))
#Step 4. "Appropriately labels the data set with descriptive variable names."
##Due to length of some variable names exceeding max length, abbreviations must be used.
featurelabels[,2]<-as.character(featurelabels[,2])
featurelabels[,2]<-gsub(x = featurelabels[,2],pattern = "Body",replacement="B",ignore.case = T)
featurelabels[,2]<-gsub(x = featurelabels[,2],pattern = "Gravity",replacement="Gr",ignore.case = T)
featurelabels[,2]<-gsub(x = featurelabels[,2],pattern = "Gyro",replacement="Gy",ignore.case = T)
featurelabels[,2]<-gsub(x = featurelabels[,2],pattern = "Jerk", replacement = "Jk",ignore.case = T)
featurelabels[,2]<-gsub(x = featurelabels[,2],pattern = "bandsEnergy",replacement = "bE",ignore.case = T)
featurelabels[,2]<-gsub(x = featurelabels[,2],pattern = "correlation",replacement = "corr",ignore.case = T)
featurelabels[,2]<-gsub(x = featurelabels[,2],pattern = "kurtosis",replacement = "Kurt",ignore.case = T)
##Once feature labels have been abbreviated, appply to full and subdata using grepl T/F vector approach.
names(fulldata)<-c(featurelabels[,2],"set","Subject","Labels")
names(subdata)<-c(featurelabels[grepl("std",x=featurelabels[,2])|grepl("mean",x = featurelabels[,2]),2],"set","Subject","Labels")
#Step 5. "From the data set in step 4, creates a second, independent tidy data set with the average of each variable for each activity and each subject."
subdatatbl<-tbl_df(data = subdata)
bysubjact<-group_by(.data = subdatatbl,Subject,Labels)
summed<-summarise_all(bysubjact,.funs = mean)
avgdata<-as.data.frame(x=summed)
#Final Step: EXPORT!
write.csv(x=subdata,file="Mean and Standard Deviation Data.csv")
write.table(x=avgdata,file="Averages by Subject and Activity Data.txt",row.names = F)
#Appendix: Appending Features File with Shorthand Version
featurelabelsfull<-(cbind(read.table(".\\features.txt",header=F),featurelabels[,2]))
names(featurelabelsfull)<-c("Index","Full","Shorthand")
write.csv(x = featurelabelsfull,file = ".\\features.txt",row.names = F)
